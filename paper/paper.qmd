---
title: "Forecasting the 2024 U.S. Presidential Election: Polling Trends and Dynamics Based on National General Election Polls"
subtitle: "Trump Consistently Leads in National Polls, with Harris Showing Sporadic Gains in Certain Polling Periods"
author: 
  - Jason Yang
  - Jerry Xia 
  - Peter Fan
thanks: "Code and data are available at: <https://github.com/Jerryx2020/US_election_prediction/tree/main>."
date: today
date-format: long
abstract: "This paper presents a predictive analysis of the 2024 U.S. Presidential Election between Kamala Harris and Donald Trump, utilizing national and state-level polling data aggregated from FiveThirtyEight. We developed a multiple linear regression model incorporating variables such as candidate support percentages, pollster reliability, sample size, poll end dates, and geographic distribution, applying recency weighting to emphasize current voter sentiment. Monte Carlo simulations were conducted to estimate the distribution of possible Electoral College outcomes, accounting for state-level variations and uncertainties in polling data. Our findings indicate that Donald Trump consistently leads in national polls, though limitations like potential polling biases and non-response errors may affect forecast accuracy."
format: pdf
header-includes: 
  - \usepackage{pdfpages}
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(usmap)
library(dplyr)
library(here)
library(ggplot2)
library(janitor)
library(knitr)
library(flextable)
library(arrow)

#Reads the data and store it into analysis_data 
analysis_data <- read_parquet(here("data/02-analysis_data/analysis_data.parquet"))
```



# Introduction

The 2024 U.S. Presidential Election stands as a pivotal moment in American politics, with widespread implications for both domestic policy and international relations. Accurately forecasting the election outcome is crucial for stakeholders ranging from policymakers to the general public. This study leverages national and state-level polling data to analyze voter sentiment toward the two main presidential candidates, Kamala Harris and Donald Trump. By focusing on polling trends since July 2024, we aim to provide an up-to-date assessment that reflects the most recent shifts in the political landscape.

To conduct our analysis, we utilize the statistical programming language R (@R), along with a suite of specialized packages that enhance data manipulation and visualization. Key libraries include the tidyverse collection (@tidyverse), which offers a cohesive set of tools for data science tasks; janitor (@janitor), which simplifies data cleaning processes; and ggplot2 (@ggplot2), renowned for its advanced plotting capabilities. These tools enable us to efficiently manage complex datasets and generate insightful visualizations that elucidate polling trends across different regions and demographics.

Our methodology involves developing a multiple linear regression model to predict candidate support percentages based on variables such as pollster reliability, sample size, poll end dates, and geographic distribution. Additionally, we implement Monte Carlo simulations to estimate the distribution of possible Electoral College outcomes, accounting for state-level variations and uncertainties inherent in polling data. By integrating these statistical techniques, we aim to provide a robust framework for election forecasting that contributes valuable insights into the dynamics of the 2024 electoral race.


# Data {#sec-data}

## Data Overview

### Scope and Relevance of the Dataset
The dataset used in this analysis is sourced from the FiveThirtyEight poll aggregation for the 2024 U.S. presidential election [@fivethirtyeight]. It focuses on polling data collected at both the national and state levels, with an emphasis on the two main presidential candidates: Kamala Harris and Donald Trump. The dataset's relevance is tied to its ability to capture voter sentiment during a highly dynamic election period, specifically from July 2024 onwards. The aim of leveraging this dataset is to develop a robust model that forecasts the election outcome by integrating trends from both the popular vote and electoral college perspectives. By concentrating on data from the official campaign period, we ensure that the dataset reflects the most current and meaningful voter preferences.

### Characteristics of the Dataset
The dataset contains a variety of features that provide a nuanced understanding of voter sentiment across different demographics and regions. Key variables include candidate name, pollster, sample size, poll end date, state (or national), and percentage support for each candidate. With approximately 3,667 observations from multiple polling organizations, the dataset is both diverse and representative, allowing for an analysis that incorporates various polling methodologies. This diversity enhances the robustness of the forecasting model, as discussed in Section 4, where the modeling approach is detailed. Including data from multiple pollsters also allows us to account for biases that may arise from differing methodologies, thereby making the model results more reliable.

### Data Collection Methodology

#### Polling Organizations and Methodologies
The polling data is aggregated from numerous organizations, each employing distinct methodologies to gather voter preferences. These pollsters are assigned numeric grades by FiveThirtyEight based on their reliability, transparency, and historical performance. By selecting only high-quality polling data, we aim to enhance the predictive power of our election model. The inclusion of a variety of polling methodologies is crucial, as it allows us to capture the nuances in voter sentiment across different regions and demographic groups, as elaborated in Section 5.2.

#### Ensuring Data Quality
To ensure data quality, a filtering process was applied to remove polls conducted by organizations with low numeric grades. Specifically, only pollsters with a numeric grade of 1 or higher were included. This threshold helps to minimize biases and inaccuracies in the data, thereby enhancing the robustness of the subsequent analysis. Additionally, pollsters with fewer than five polls were excluded to avoid unreliable estimates, ensuring that only consistent and representative polling data are used.

### Data Cleaning Process

#### Initial Data Cleaning and Transformations
The raw data was subjected to multiple cleaning steps to prepare it for analysis. First, duplicate entries were removed, and column names were standardized for consistency. Key variables, such as candidate name, pollster, sample size, and poll end date, were retained, while irrelevant or redundant information was discarded. Additionally, the state variable was adjusted to aggregate specific districts—such as Nebraska CD-2 and Maine CD-1—into their respective states to facilitate streamlined geographic analysis. This transformation is essential for creating a consistent dataset that aligns with the electoral college framework discussed in Section 6.

```{r visualize-sample-size}
#| warning: false
#| message: false
#| echo: false
# Ensure 'analysis_data' is already loaded at this point
ggplot(analysis_data, aes(x = sample_size)) +
  geom_histogram(binwidth = 100, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Sample Sizes in Polls", 
       x = "Sample Size", 
       y = "Frequency") +
  theme_minimal()



```

This histogram (Figure 2.1) illustrates the distribution of sample sizes across all polls, highlighting the variability in poll sizes. Larger sample sizes are generally associated with more reliable polls, which is critical for making robust predictions.

#### Addressing Missing Data
Handling missing data was a critical step to ensure dataset completeness. Missing values were primarily found in the state column, which were replaced with "National" to denote national-level polls. Rows with missing information in key variables (e.g., candidate name or sample size) were removed. This approach ensured that the dataset was both complete and reliable for further analysis, as incomplete data could introduce biases into the model.

### Key Variables and Derived Features

#### Description of Key Variables
The key variables retained for analysis include:
- **Candidate Name**: Indicates the candidate (either Kamala Harris or Donald Trump) for whom polling data is reported.
- **Pollster**: The organization conducting the poll, which is used to assess the quality and reliability of the poll.
- **Sample Size**: Represents the number of respondents surveyed in each poll, which impacts the poll's margin of error.
- **End Date**: The date when polling ended, used to calculate recency and weigh polls accordingly.
- **State**: Specifies whether the poll is conducted at the state level or is national in scope.
- **Percentage Support (pct)**: The percentage of respondents supporting each candidate, which serves as the primary measure of voter preference.

```{r}
#| warning: false
#| message: false
#| echo: false
# Visualization: Candidate Support by State
filtered_data <- analysis_data %>% filter(state != "National")
ggplot(filtered_data, aes(x = state, y = pct, fill = candidate_name)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Candidate Support by State", 
       x = "State", 
       y = "Percentage Support") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1), 
        legend.position = "top")

```

Figure 2.2 displays the percentage support for each candidate across different states. This visualization helps identify regional strengths and weaknesses for both candidates, providing a more granular view of voter sentiment.
```{r}
#| warning: false
#| message: false
#| echo: false


if (!require(usmap)) install.packages("usmap")
if (!require(ggplot2)) install.packages("ggplot2")
if (!require(dplyr)) install.packages("dplyr")
if (!require(readr)) install.packages("readr")
state_support_stats <- read_parquet(here("data/04-electoral_college_estimate/states_support.parquet"))
winners <- state_support_stats %>%
  group_by(state) %>%
  filter(avg_support == max(avg_support)) %>%
  ungroup()

# Convert state names to abbreviations (required by usmap)
winners$abbr <- state.abb[match(winners$state, state.name)]

all_states <- state.name

# Find the states present in the winners data
states_in_winners <- unique(winners$state)

# Find the missing states by comparing with the list of all states
missing_states <- setdiff(all_states, states_in_winners)

# Create a data frame for the missing states with "Uncertainty" as the candidate
missing_states_df <- data.frame(
  state = missing_states,
  candidate_name = "Uncertainty",
  avg_support = NA,  # Since we don't have support data for missing states
  sd_support = NA,
  electoral_votes = NA,
  abbr = state.abb[match(missing_states, state.name)] # Add state abbreviations
)

# Add the missing states to the winners dataset
winners <- bind_rows(winners, missing_states_df)

# Change Nebraska's candidate to "Uncertainty" for all entries
winners <- winners %>%
  mutate(candidate_name = ifelse(state == "Nebraska", "Uncertainty", candidate_name))

# Remove duplicate entries for Nebraska, keeping only one
winners <- winners %>%
  distinct(state, .keep_all = TRUE)

plot_usmap(data = winners, values = "candidate_name", regions = "states") +
  scale_fill_manual(values = c("Donald Trump" = "red", "Kamala Harris" = "blue", "Uncertainty" = "grey")) +
  labs(title = "2024 U.S. Presidential Election: State Winners",
       fill = "Candidate") +
  theme(legend.position = "right")

```


#### Variable Transformations and Feature Engineering
Several transformations were applied to prepare the data for modeling. Dates were standardized using the `lubridate` package to ensure uniformity across observations. Geographic transformations were also performed by aggregating specific state districts to their respective states, which simplified the geographic analysis and aligned with the electoral college modeling approach. Additionally, a new feature called **Recency** was engineered, representing the number of days since the most recent poll. This feature allows the model to weigh more recent polls more heavily, as explained in Section 4.3.

### Filtering Criteria and Data Selection

#### Timeframe Filtering
To maintain the dataset's relevance to the current election cycle, polling data collected before July 21, 2024 (the official declaration of Kamala Harris's candidacy), was excluded. This filtering step was crucial for ensuring that the dataset reflects voter sentiment during the official campaign period. By focusing on this timeframe, the analysis becomes more representative of the dynamics that are most likely to influence the election outcome.

#### Pollster Reliability Filtering
As previously mentioned in Section 2.3.2, only pollsters with a numeric grade of 1 or higher were included. This criterion was set to enhance the reliability of the dataset and to focus on data sources that have historically shown accuracy in predicting election outcomes. Furthermore, pollsters with fewer than five conducted polls were excluded to avoid potential biases from underrepresented data sources.

### Recency and Its Importance in Poll Weighting

#### Calculating Recency
Recency was calculated as the number of days between the reference date (the most recent poll in the dataset) and the poll end date. This calculation was used to create a recency weight for each poll, with more recent polls receiving higher weights. This weighting mechanism is essential for accurately forecasting voter preferences, as it allows the model to place greater emphasis on current data.

#### Application of Recency Weights
The recency weights were applied during the modeling process to account for the evolving nature of voter sentiment. By incorporating recency, the model becomes more adaptive to recent changes in voter preferences, which is particularly important given the rapidly changing political landscape. The use of recency weighting is further discussed in Section 4.4, where we elaborate on the modeling approach and its implications for forecast accuracy.

### Summary and Visualization of Cleaned Data

#### Cleaned Dataset Overview
The final cleaned dataset contains approximately 3,000 observations, each representing a unique poll. The dataset includes details such as sample sizes, pollster information, candidate support percentages, and geographic coverage. This refined dataset serves as a robust foundation for the subsequent modeling and analysis steps, as described in Section 4.

#### Data Visualization
To gain insights into the distribution of key variables, visualizations such as histograms and bar charts were created. For instance, a histogram of **Sample Size** helps illustrate the variability in poll sizes, while bar charts displaying **Percentage Support** for each candidate across different states provide a clearer understanding of regional dynamics. These visualizations are included in the exploratory data analysis (Section 3) to help identify underlying trends and patterns in the dataset. The visualizations were created using `ggplot2` [@ggplot2], ensuring that they are both informative and visually appealing, similar to the standards set by


Overview text

## Measurement





## Outcome variables

In this analysis, the outcome variable of interest is the percentage of support a candidate receives in each poll, represented by pct. This variable indicates the proportion of respondents within a poll who favor a particular candidate, measured as a percentage. Given that pct serves as a continuous variable bounded between 0 and 100, it is well-suited for modeling the levels of support across different polls and over time.


## Predictor variables

To accurately predict the 2024 Presidential Election, we have identified several key variables that capture a range of factors influencing voter behavior. These predictor variables include: 

- Polling Percentage (PCT): Represents the percentage of respondents in a poll who support a specific candidate
- Pollster: Represents the name of the polling organization that conducted the poll. 
- Candidate: The name of the candidate in the poll
- Sample Size (sample_size): size of the respondents participating in the poll
- State (state): the state of the poll was taken in 
- End_date: the day the poll ended


# Model

This analysis employs predictive models to estimate the anticipated support for the two major candidates in the 2024 U.S. Presidential Election: a multiple linear regression model. These models use high-quality polling data from reputable sources, with relevant predictors to provide insights into public opinion trends.


## Model set-up

The multiple linear regression model is designed to predict the candidate's percentage of support (pct) as a linear function of various predictors. Formally, we define the model as:

\begin{align*}
\text{pct}_i &= \beta_0 + \beta_1 \cdot \text{pollster}_i + \beta_2 \cdot \text{sample\_size}_i + \sum_{k=1}^{K} \delta_k \cdot \text{state}_{ik} + \beta_4 \cdot \text{end\_date}_i + \beta_5 \cdot \text{candidate}_i + \epsilon_i,
\end{align*}

Where 

- $\beta_0$ is the expected value of PCT when all predictor variables are zero, intercept 
- $\beta_1$ captures the effect pollsters have on the response variable 
- $\beta_2$ captures the effect sample_size have on the response variable
- $\delta_k$ captures the difference in PCT between states
- $\beta_4$ captures the expected change in PCT for each additional unit increase in the end date variable 
- $\beta_5$ captures the difference in PCT associated with difference candidates 


### Model justification

Predictors Selection: Variables such as sample_size, pollster, and state are included to capture systematic differences in polling methods and geographic variations in support. The date (end_date) of each poll controls for temporal effects on candidate popularity.

Linear regression was chosen for this analysis due to several key advantages. First, its simplicity and interpret ability make it highly suitable for examining the relationship between predictor variables and the response variable, specifically the candidate support percentage. Each coefficient in a linear regression model clearly represents the influence of a predictor on the outcome, which facilitates straightforward interpretation and communication of results. Moreover, linear regression is computationally efficient, making it ideal for rapid model estimation, tuning, and testing, even on relatively large datasets.

## Regression Assumptions 
- Linearity: The relationship between each predictor and the response (pct) is assumed to be linear.
- Normality: Errors are assumed to follow a normal distribution, which is tested during model diagnostics.

### Checking Assumptions 

In the Residuals vs. Fitted, there is no clear curved pattern, which suggests that the linear relationship might be appropriate. However, there are some clusters and a slight spread, which may indicate minor issues in capturing the relationship fully. Secondly, in the qqnorm plot, the points closely follow the diagonal line, indicating that residuals are approximately normal. This supports the normality assumption of the residuals, which is essential for reliable inference in linear regression. 

## Results 

# Discussion

## Purpose 

This paper analyzes and predicts the 2024 U.S. presidential election by fitting a regression model based on polling data downloaded from FiveThirtyEight (@fivethirtyeight). Our analysis focuses on the leading candidates, examining key variables such as the pollster, the date the poll was conducted, sample size, and the percentage of respondents supporting each candidate. 

Additionally, this analysis aimed to estimate the 2024 U.S. presidential election electoral college outcome by propagating uncertainty through polling data. Using Monte Carlo simulations, we captured the variability in candidate support across states and produced a distribution of possible electoral outcomes. This integration enabled us to estimate electoral votes for each candidate by state, taking into account each state's unique polling landscape. 

## Limitations 

While Monte Carlo simulations provide a robust framework for propagating uncertainty, the reliability of our estimates is reliant upon the accuracy and representatives of polling data. 

As our estimates are contingent upon the accuracy and representativeness of polling data, we cannot guarantee absolute precision in our projections. Nate Silver (2024) highlights a particular challenge in polling known as "herding," where polling organizations may unintentionally align their results to avoid being statistical outliers (@NYMagHerding2024).This alignment can distort the true range of our estimates. Since our projections suggest that Trump would win, it’s important to address the role of standard deviations in our estimates and consider the possibility that Harris’s support may be underestimated, similar to how Trump’s support was in 2020 (@FTArticle2024). The idea of Harris being underestimated, much like Trump was in 2020, hinges on the possibility that polling errors or biases could be systematically missing certain groups of voters who support her. In 2020, Trump’s support was underestimated in some key swing states due to factors such as nonresponse bias, where Trump-leaning voters were less likely to participate in polls, and demographic weighting errors. 




\newpage

\appendix

# Appendix {-}

# Pollster Analysis

The Marquette Law School Poll utilizes a rigorous probability-based methodology to conduct a national question survey of adults across the United States. This method combines address-based sampling (ABS), which uses the U.S. Postal Service's Computerized Delivery Sequence (CDS), and stratified random sampling, which covers virtually all residential addresses and is able to reach the offline population, thereby reducing the bias associated with surveys conducted solely via the Internet [@citemarquette]. The stratified random sampling method divides the population into subgroups (e.g., age, gender, education), to make sure that each subgroup is proportionately represented in the sample. This structure improves representativeness and accuracy, thereby supporting valid inferences about the total U.S. adult population.

## What is the population, frame, and sample?

The population surveyed by the Marquette Law School Poll includes all U.S. adults aged 18 and older, living in the 50 states and D.C. The sampling frame was developed using Address-Based Sampling (ABS) by using the U.S. Postal Service’s Computerized Delivery Sequence (CDS) file—a regularly updated, near-complete listing of all residential addresses in the U.S., excluding business addresses. This frame can cover almost every U.S. household, including non-internet and traditionally hard-to-reach areas [@citemarquette]. 

The sample itself was drawn from the SSRS Opinion Panel, a probability-based panel that combines participants from ABS and a bilingual telephone survey conducted through the SSRS Omnibus. This dual recruitment strategy, which includes participants from both internet and non-internet households, improves demographic inclusivity. To achieve accurate representation, the survey sampled 1,005 adults, including registered and likely voters, and applied post-stratification weighting to adjust for demographic imbalances. This weighting aligns the sample with key population parameters, ensuring that the poll’s findings are as representative as possible of the broader adult population.

## How is the sample recruited?

Marquette Law School Poll using the SSRS Opinion Panel for the recruitment, a probability-based panel integrating Address-Based Sampling (ABS) and telephone survey data from the SSRS Omnibus, a nationally representative bilingual survey platform. This dual recruitment approach ensures that both internet and non-internet users are included, addressing the online-only bias often seen in web-based surveys and thereby enhancing sample inclusivity [@citemarquette].

The Marquette Law School Poll uses stratified sampling to obtain a balanced and representative sample by differentiating participants based on key demographic variables such as age, gender, race, education, region, and political affiliation. The poll then ensures proportional representation of key demographic groups, which reduces the risk of sampling bias and increases the generalizability of the results.

Selected participants received a unique survey link through email invitations. Non-responders were sent up to two reminder emails, and, for those who opted in, a text notification reminder. To encourage completion and maintain high response rates, participants were offered an e-gift card as an incentive. This use of reminders and incentives is critical in minimizing non-response bias, thereby strengthening the reliability of the poll’s findings.

## What sampling approach is taken, and what are some of the trade-offs of this?

The Marquette Law School Poll uses both sampling probability sampling methods, address-based sampling (ABS) and stratified random sampling, this can increase representativeness and inclusiveness. ABS uses the U.S. Postal Service's Computerized Delivery Sequence (CDS), which covers nearly all residential addresses in the U.S., including homes with no Internet access. This approach is critical to minimizing the coverage bias associated with web-only surveys [@citemarquette].

The poll also applies stratified random sampling to ensure that key demographic groups—such as age, gender, race, education, region, and political affiliation—are proportionally represented within the sample. Samples are taken from each subgroup once the population is divided into subgroups using stratified sampling. Consequently, sampling error is reduced and the sample findings accurately represent the views of each subgroup.

While this approach increases the reliability and representativeness of the findings, it also demands significant resources. ABS requires comprehensive address data and ongoing maintenance, while stratification and post-stratification weighting add complexity to both survey design and data processing. These resource-intensive processes make ABS and stratified random sampling more costly than simpler sampling methods but are justified by the improved accuracy and generalizability of the poll’s results.

## How is non-response handled?

The Marquette Law School Poll applies weighting adjustments across demographic factors, including age, gender, race, education, region, and internet access, aligning the sample’s characteristics with those of the broader adult population [@citemarquette]. This can represent the under-represented groups more accurately and increase the weight of these respondents. This process enhances the survey’s representativeness, ensuring findings reflect the national population reliably despite disparities in response rates.

## What is good and bad about the questionnaire?

The Marquette Law School Poll is designed to boost respondent engagement and minimize survey fatigue. Using skip patterns that adapt questions based on previous answers, the survey reduces cognitive load, streamlines flow and lowers dropout rates by customizing the survey experience [@citemarquette]. This probability-based approach, supplemented by comprehensive weighting and stratification, further makes sure that the results accurately represent the U.S. adult population, with clear and straightforward questions that enhance accessibility across demographic groups.

However, despite ABS and telephone recruitment efforts, the reliance on web-based responses can cause some internet bias possibly underrepresenting households with no internet access. Additionally, the survey’s length and complexity could add to respondent fatigue, potentially impacting response quality as participants progress. The response rate of approximately 47.4% reflects moderate attrition, typical in public opinion research, highlighting the necessity of post-stratification adjustments to address any demographic imbalances from non-response.

# Idealized Methodology 

In designing a forecast for the upcoming US presidential election with a $100,000 budget, our methodology focuses on creating a representative survey that captures the voting intentions of likely voters across the United States. The objective is to gather reliable, high-quality data that supports a well-informed forecast through effective sampling, data validation, and aggregation techniques.

Our target population is voters aged 18 and above, with a sample size of approximately 10,000 responses, 200 responses from each state, to ensure  statistical significance at the national level and within key demographic groups. To achieve balanced representation, we will employ stratified random sampling based on age, gender, race/ethnicity, education, region, and urban/rural status. This approach will involve weighting responses using recent census data and voter turnout statistics to address any demographic discrepancies. 

We will combine online survey panels, social media outreach, and targeted telephone recruitment. These methods are chosen to increase accessibility for harder-to-reach demographics, such as older adults and rural residents. To encourage participation, we will offer modest incentives, such as a small monetary compensation or entry into a prize draw. All data collection will be conducted through a reliable survey platform—Google Forms. 

The survey itself will be concise and straightforward, focusing on voting intentions, key issues, and demographic information. For data validation, the survey will include attention-check questions as respondents are very likely to complete the form for an entry into a prize draw. We will also conduct multiple waves of the survey, we will adopt a "poll-of-polls" approach, aggregating responses from different waves while applying weights based on relevance. 

To mitigate biases such as non-response bias, social desirability bias, and order bias, our team will implement several strategies. We will send reminders to non-respondents to encourage participation, emphasizing the prize draw incentives to increase response rates. Survey questions will be carefully crafted to maintain neutral wording and avoid sensitive topics that might discourage honest responses. Additionally, within each wave of polls, we will randomize the order of questions to minimize the impact of question order on responses. These measures aim to enhance the reliability and accuracy of our survey results. 

To ensure data validity, IP addresses would be recorded to prevent multiple submissions from the same source. Additionally, cookies would be implemented to prevent users from retaking the survey on the same device. Finally, we will verify respondents' email addresses to ensure uniqueness.

Ethically, our approach prioritizes respondent privacy and data security. We will ensure that participants’ responses remain anonymous and that all data is handled securely. Transparency is also essential; respondents will be informed about the survey’s sponsorship, methodology, and data use.

The survey will be implemented on Google Forms, with a link provided in the appendix. We also included the questions in the appendix for better understandings. 

## Budget Allocation 

- Sampling and Data Collection (Advertisements and Recruitment Platforms): $40,000
- Participant Incentives (Prize Pool): $20,000
- Survey Design and Testing: $20,000
- Data Analysis and Validation: $20,000

# Idealized Survey 

The proposed survey is designed using Google Forms,
https://forms.gle/Vhmm1b1XnqTSoBWq8


## Survey Copy 

\includepdf[pages=-]{../other/survey/survey.pdf}



\newpage


# References


