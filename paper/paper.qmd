---
title: "Forecasting the 2024 U.S. Presidential Election: Polling Trends and Dynamics Based on National General Election Polls"
subtitle: "Trump Consistently Leads in National Polls, with Harris Showing Sporadic Gains in Certain Polling Periods"
author: 
  - Jason Yang
  - Jerry Xia 
  - Peter Fan
thanks: "Code and data are available at: <https://github.com/Jerryx2020/US_election_prediction/tree/main>."
date: today
date-format: long
abstract: ""
format: pdf
header-includes: 
  - \usepackage{pdfpages}
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(usmap)
library(dplyr)
library(here)
library(ggplot2)
library(janitor)
library(knitr)
library(flextable)
```


# Introduction

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....


# Data {#sec-data}

## Overview

The dataset used for this analysis was sourced from FiveThirtyEight’s poll aggregation platform, which compiles high-quality polling data from various reputable pollsters across the U.S. (@fivethirtyeight). This analysis uses the statistical programming language R (@R) and various libraries for data manipulation and visualization, including tidyverse for efficient data wrangling and ggplot2 for creating insightful visualizations (@tidyverse, @ggplot2). By employing robust statistical methods and tools, this analysis seeks to forecast potential outcomes of the 2024 U.S. Presidential Election. 

Overview text

## Measurement





## Outcome variables

In this analysis, the outcome variable of interest is the percentage of support a candidate receives in each poll, represented by pct. This variable indicates the proportion of respondents within a poll who favor a particular candidate, measured as a percentage. Given that pct serves as a continuous variable bounded between 0 and 100, it is well-suited for modeling the levels of support across different polls and over time.


## Predictor variables

To accurately predict the 2024 Presidential Election, we have identified several key variables that capture a range of factors influencing voter behavior. These predictor variables include: 

- Polling Percentage (PCT): Represents the percentage of respondents in a poll who support a specific candidate
- Pollster: Represents the name of the polling organization that conducted the poll. 
- Candidate: The name of the candidate in the poll
- Sample Size (sample_size): size of the respondents participating in the poll
- State (state): the state of the poll was taken in 
- End_date: the day the poll ended


# Model

This analysis employs predictive models to estimate the anticipated support for the two major candidates in the 2024 U.S. Presidential Election: a multiple linear regression model. These models use high-quality polling data from reputable sources, with relevant predictors to provide insights into public opinion trends.


## Model set-up

The multiple linear regression model is designed to predict the candidate's percentage of support (pct) as a linear function of various predictors. Formally, we define the model as:

\begin{align*}
\text{pct}_i &= \beta_0 + \beta_1 \cdot \text{pollster}_i + \beta_2 \cdot \text{sample\_size}_i + \sum_{k=1}^{K} \delta_k \cdot \text{state}_{ik} + \beta_4 \cdot \text{end\_date}_i + \beta_5 \cdot \text{candidate}_i + \epsilon_i,
\end{align*}

Where 

- $\beta_0$ is the expected value of PCT when all predictor variables are zero, intercept 
- $\beta_1$ captures the effect pollsters have on the response variable 
- $\beta_2$ captures the effect sample_size have on the response variable
- $\delta_k$ captures the difference in PCT between states
- $\beta_4$ captures the expected change in PCT for each additional unit increase in the end date variable 
- $\beta_5$ captures the difference in PCT associated with difference candidates 


### Model justification

Predictors Selection: Variables such as sample_size, pollster, and state are included to capture systematic differences in polling methods and geographic variations in support. The date (end_date) of each poll controls for temporal effects on candidate popularity.

Linear regression was chosen for this analysis due to several key advantages. First, its simplicity and interpret ability make it highly suitable for examining the relationship between predictor variables and the response variable, specifically the candidate support percentage. Each coefficient in a linear regression model clearly represents the influence of a predictor on the outcome, which facilitates straightforward interpretation and communication of results. Moreover, linear regression is computationally efficient, making it ideal for rapid model estimation, tuning, and testing, even on relatively large datasets.

## Regression Assumptions 
- Linearity: The relationship between each predictor and the response (pct) is assumed to be linear.
- Normality: Errors are assumed to follow a normal distribution, which is tested during model diagnostics.

### Checking Assumptions 

In the Residuals vs. Fitted, there is no clear curved pattern, which suggests that the linear relationship might be appropriate. However, there are some clusters and a slight spread, which may indicate minor issues in capturing the relationship fully. Secondly, in the qqnorm plot, the points closely follow the diagonal line, indicating that residuals are approximately normal. This supports the normality assumption of the residuals, which is essential for reliable inference in linear regression. 

## Results 


# Discussion





\newpage

\appendix

# Appendix {-}

# Pollster Analysis

The Marquette Law School Poll utilizes a rigorous probability-based methodology to conduct a national question survey of adults across the United States. This method combines address-based sampling (ABS), which uses the U.S. Postal Service's Computerized Delivery Sequence (CDS), and stratified random sampling, which covers virtually all residential addresses and is able to reach the offline population, thereby reducing the bias associated with surveys conducted solely via the Internet [@citemarquette]. The stratified random sampling method divides the population into subgroups (e.g., age, gender, education), to make sure that each subgroup is proportionately represented in the sample. This structure improves representativeness and accuracy, thereby supporting valid inferences about the total U.S. adult population.

## What is the population, frame, and sample?

The population surveyed by the Marquette Law School Poll includes all U.S. adults aged 18 and older, living in the 50 states and D.C. The sampling frame was developed using Address-Based Sampling (ABS) by using the U.S. Postal Service’s Computerized Delivery Sequence (CDS) file—a regularly updated, near-complete listing of all residential addresses in the U.S., excluding business addresses. This frame can cover almost every U.S. household, including non-internet and traditionally hard-to-reach areas [@citemarquette]. 

The sample itself was drawn from the SSRS Opinion Panel, a probability-based panel that combines participants from ABS and a bilingual telephone survey conducted through the SSRS Omnibus. This dual recruitment strategy, which includes participants from both internet and non-internet households, improves demographic inclusivity. To achieve accurate representation, the survey sampled 1,005 adults, including registered and likely voters, and applied post-stratification weighting to adjust for demographic imbalances. This weighting aligns the sample with key population parameters, ensuring that the poll’s findings are as representative as possible of the broader adult population.

## How is the sample recruited?

Marquette Law School Poll using the SSRS Opinion Panel for the recruitment, a probability-based panel integrating Address-Based Sampling (ABS) and telephone survey data from the SSRS Omnibus, a nationally representative bilingual survey platform. This dual recruitment approach ensures that both internet and non-internet users are included, addressing the online-only bias often seen in web-based surveys and thereby enhancing sample inclusivity [@citemarquette].

The Marquette Law School Poll uses stratified sampling to obtain a balanced and representative sample by differentiating participants based on key demographic variables such as age, gender, race, education, region, and political affiliation. The poll then ensures proportional representation of key demographic groups, which reduces the risk of sampling bias and increases the generalizability of the results.

Selected participants received a unique survey link through email invitations. Non-responders were sent up to two reminder emails, and, for those who opted in, a text notification reminder. To encourage completion and maintain high response rates, participants were offered an e-gift card as an incentive. This use of reminders and incentives is critical in minimizing non-response bias, thereby strengthening the reliability of the poll’s findings.

## What sampling approach is taken, and what are some of the trade-offs of this?

The Marquette Law School Poll uses both sampling probability sampling methods, address-based sampling (ABS) and stratified random sampling, this can increase representativeness and inclusiveness. ABS uses the U.S. Postal Service's Computerized Delivery Sequence (CDS), which covers nearly all residential addresses in the U.S., including homes with no Internet access. This approach is critical to minimizing the coverage bias associated with web-only surveys [@citemarquette].

The poll also applies stratified random sampling to ensure that key demographic groups—such as age, gender, race, education, region, and political affiliation—are proportionally represented within the sample. Samples are taken from each subgroup once the population is divided into subgroups using stratified sampling. Consequently, sampling error is reduced and the sample findings accurately represent the views of each subgroup.

While this approach increases the reliability and representativeness of the findings, it also demands significant resources. ABS requires comprehensive address data and ongoing maintenance, while stratification and post-stratification weighting add complexity to both survey design and data processing. These resource-intensive processes make ABS and stratified random sampling more costly than simpler sampling methods but are justified by the improved accuracy and generalizability of the poll’s results.

## How is non-response handled?

The Marquette Law School Poll applies weighting adjustments across demographic factors, including age, gender, race, education, region, and internet access, aligning the sample’s characteristics with those of the broader adult population [@citemarquette]. This can represent the under-represented groups more accurately and increase the weight of these respondents. This process enhances the survey’s representativeness, ensuring findings reflect the national population reliably despite disparities in response rates.

## What is good and bad about the questionnaire?

The Marquette Law School Poll is designed to boost respondent engagement and minimize survey fatigue. Using skip patterns that adapt questions based on previous answers, the survey reduces cognitive load, streamlines flow and lowers dropout rates by customizing the survey experience [@citemarquette]. This probability-based approach, supplemented by comprehensive weighting and stratification, further makes sure that the results accurately represent the U.S. adult population, with clear and straightforward questions that enhance accessibility across demographic groups.

However, despite ABS and telephone recruitment efforts, the reliance on web-based responses can cause some internet bias possibly underrepresenting households with no internet access. Additionally, the survey’s length and complexity could add to respondent fatigue, potentially impacting response quality as participants progress. The response rate of approximately 47.4% reflects moderate attrition, typical in public opinion research, highlighting the necessity of post-stratification adjustments to address any demographic imbalances from non-response.

# Idealized Methodology 

In designing a forecast for the upcoming US presidential election with a $100,000 budget, our methodology focuses on creating a representative survey that captures the voting intentions of likely voters across the United States. The objective is to gather reliable, high-quality data that supports a well-informed forecast through effective sampling, data validation, and aggregation techniques.

Our target population is voters aged 18 and above, with a sample size of approximately 10,000 responses, 200 responses from each state, to ensure  statistical significance at the national level and within key demographic groups. To achieve balanced representation, we will employ stratified random sampling based on age, gender, race/ethnicity, education, region, and urban/rural status. This approach will involve weighting responses using recent census data and voter turnout statistics to address any demographic discrepancies. 

We will combine online survey panels, social media outreach, and targeted telephone recruitment. These methods are chosen to increase accessibility for harder-to-reach demographics, such as older adults and rural residents. To encourage participation, we will offer modest incentives, such as a small monetary compensation or entry into a prize draw. All data collection will be conducted through a reliable survey platform—Google Forms. 

The survey itself will be concise and straightforward, focusing on voting intentions, key issues, and demographic information. For data validation, the survey will include attention-check questions as respondents are very likely to complete the form for an entry into a prize draw. We will also conduct multiple waves of the survey, we will adopt a "poll-of-polls" approach, aggregating responses from different waves while applying weights based on relevance. 

To mitigate biases such as non-response bias, social desirability bias, and order bias, our team will implement several strategies. We will send reminders to non-respondents to encourage participation, emphasizing the prize draw incentives to increase response rates. Survey questions will be carefully crafted to maintain neutral wording and avoid sensitive topics that might discourage honest responses. Additionally, within each wave of polls, we will randomize the order of questions to minimize the impact of question order on responses. These measures aim to enhance the reliability and accuracy of our survey results. 

To ensure data validity, IP addresses would be recorded to prevent multiple submissions from the same source. Additionally, cookies would be implemented to prevent users from retaking the survey on the same device. Finally, we will verify respondents' email addresses to ensure uniqueness.

Ethically, our approach prioritizes respondent privacy and data security. We will ensure that participants’ responses remain anonymous and that all data is handled securely. Transparency is also essential; respondents will be informed about the survey’s sponsorship, methodology, and data use.

The survey will be implemented on Google Forms, with a link provided in the appendix. We also included the questions in the appendix for better understandings. 

## Budget Allocation 

- Sampling and Data Collection (Advertisements and Recruitment Platforms): $40,000
- Participant Incentives (Prize Pool): $20,000
- Survey Design and Testing: $20,000
- Data Analysis and Validation: $20,000

# Idealized Survey 

The proposed survey is designed using Google Forms,
https://forms.gle/Vhmm1b1XnqTSoBWq8


## Survey Copy 

\includepdf[pages=-]{../other/survey/survey.pdf}



\newpage


# References


