---
title: "Forecasting the 2024 U.S. Presidential Election"
author: 
  - Jason Yang
  - Jerry Xia 
  - Peter Fan
thanks: "Code and data are available at: [https://github.com/Jerryx2020/US_election_prediction/tree/main]."
date: "`r format(Sys.Date() - 1, '%A, %B %d, %Y')`" #chatgpt assisted how to create a custom date for due date November 4
date-format: long
abstract: ""
format: pdf
header-includes: 
  - \usepackage{pdfpages}
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(usmap)
library(dplyr)
library(here)
library(ggplot2)
library(janitor)
library(knitr)
library(flextable)
```


# Introduction

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....


# Data {#sec-data}

## Overview

The dataset used for this analysis was sourced from FiveThirtyEight’s poll aggregation platform, which compiles high-quality polling data from various reputable pollsters across the U.S. (@fivethirtyeight). This analysis uses the statistical programming language R (@R) and various libraries for data manipulation and visualization, including tidyverse for efficient data wrangling and ggplot2 for creating insightful visualizations (@tidyverse, @ggplot2). By employing robust statistical methods and tools, this analysis seeks to forecast potential outcomes of the 2024 U.S. Presidential Election. 

Overview text

## Measurement





## Outcome variables

In this analysis, the outcome variable of interest is the percentage of support a candidate receives in each poll, represented by pct. This variable indicates the proportion of respondents within a poll who favor a particular candidate, measured as a percentage. Given that pct serves as a continuous variable bounded between 0 and 100, it is well-suited for modeling the levels of support across different polls and over time.


## Predictor variables

To accurately predict the 2024 Presidential Election, we have identified several key variables that capture a range of factors influencing voter behavior. These predictor variables include: 

- Polling Percentage (PCT): Represents the percentage of respondents in a poll who support a specific candidate
- Pollster: Represents the name of the polling organization that conducted the poll. 
- Candidate: The name of the candidate in the poll
- Sample Size (sample_size): size of the respondents participating in the poll
- State (state): the state of the poll was taken in 
- End_date: the day the poll ended
- Start_date: the day the poll started 


# Model

This analysis employs predictive models to estimate the anticipated support for the two major candidates in the 2024 U.S. Presidential Election: a multiple linear regression model. These models use high-quality polling data from reputable sources, with relevant predictors to provide insights into public opinion trends.


## Model set-up

The multiple linear regression model is designed to predict the candidate's percentage of support (pct) as a linear function of various predictors. Formally, we define the model as:

\begin{align*}
\text{pct}_i &= \beta_0 + \beta_1 \cdot \text{pollster}_i + \beta_2 \cdot \text{sample\_size}_i + \sum_{k=1}^{K} \delta_k \cdot \text{state}_{ik} + \beta_4 \cdot \text{end\_date}_i + \beta_5 \cdot \text{candidate}_i + \epsilon_i,
\end{align*}

Where 

- $\beta_0$ is the expected value of PCT when all predictor variables are zero, intercept 
- $\beta_1$ captures the effect pollsters have on the response variable 
- $\beta_2$ captures the effect sample_size have on the response variable
- $\delta_k$ captures the difference in PCT between states
- $\beta_4$ captures the expected change in PCT for each additional unit increase in the end date variable 
- $\beta_5$ captures the difference in PCT associated with difference candidates 


### Model justification

Predictors Selection: Variables such as sample_size, pollster, and state are included to capture systematic differences in polling methods and geographic variations in support. The date (end_date) of each poll controls for temporal effects on candidate popularity.

Linear regression was chosen for this analysis due to several key advantages. First, its simplicity and interpret ability make it highly suitable for examining the relationship between predictor variables and the response variable, specifically the candidate support percentage. Each coefficient in a linear regression model clearly represents the influence of a predictor on the outcome, which facilitates straightforward interpretation and communication of results. Moreover, linear regression is computationally efficient, making it ideal for rapid model estimation, tuning, and testing, even on relatively large datasets.

## Regression Assumptions 
- Linearity: The relationship between each predictor and the response (pct) is assumed to be linear.
- Normality: Errors are assumed to follow a normal distribution, which is tested during model diagnostics.

### Checking Assumptions 

In the Residuals vs. Fitted, there is no clear curved pattern, which suggests that the linear relationship might be appropriate. However, there are some clusters and a slight spread, which may indicate minor issues in capturing the relationship fully. Secondly, in the qqnorm plot, the points closely follow the diagonal line, indicating that residuals are approximately normal. This supports the normality assumption of the residuals, which is essential for reliable inference in linear regression. 

## Results 


# Discussion





\newpage

\appendix

# Appendix {-}

# Pollster Analysis

The Marquette Law School Poll employs a rigorous methodology to survey adults in the US on national issues, incorporating probability-based sampling that combines Address-Based Sampling (ABS) and Stratified Random Sampling [@citemarquette]. This approach, including online and offline respondents, ensures broad representativeness. The SSRS Polling Panel supports participant recruitment, and weighting adjustments enhance result accuracy.

## What is the population, frame, and sample?

The population for the poll includes adults aged 18 and over across all 50 states and the District of Columbia. The sampling frame was constructed through ABS, leveraging the US Postal Service's Computerized Delivery Sequence (CDS), a comprehensive, regularly updated list of residential addresses. The primary source for participants is the SSRS Opinion Panel, which includes both ABS and telephone survey data to capture hard-to-reach demographics, like non-internet users. The survey ultimately included 1,005 adults, including registered and likely voters, with weighted samples to ensure proportional representation [@citemarquette].

## How is the sample recruited?

Participants were recruited via the SSRS Omnibus Panel, a probability panel formed from ABS and telephone survey data. This dual approach ensured that both internet and non-internet users were included, minimizing online-only bias. Stratified by demographics (age, gender, race, education, region, and partisan affiliation), this process produced a balanced representation across groups. Selected participants received an email invitation with a unique link to the survey. Non-responders received up to two reminder emails, and those who opted for text notifications also received reminders. Participants received an e-gift card incentive upon survey completion [@citemarquette].

## What sampling approach is taken, and what are some of the trade-offs of this?

The Marquette Law School Poll combines ABS and stratified random sampling. The ABS covers all residential addresses using USPS delivery sequences, ensuring broad geographic reach. To include hard-to-reach demographics, SSRS supplements ABS data with telephone survey responses. Stratified sampling by key demographics (age, gender, race, education, region, and political party) ensures representation across major groups [@citemarquette]. This probability-based sampling minimizes bias but requires significant resources. Stratification and weighting to represent specific populations add to survey complexity and cost.

## How is non-response handled?

To address non-response and improve representativeness, SSRS applies weighting adjustments based on demographic variables such as age, gender, race, education, region, and internet use [@citemarquette]. This process aligns sample characteristics with adult population parameters, reducing bias from demographic differences in response rates.

## What is good and bad about the questionnaire?

The questionnaire is well-designed, with a collaborative approach that reduces respondent burden and improves comprehension. A thoughtfully structured skip pattern enhances flow and minimizes dropout rates. The probability-based sampling, combined with extensive weighting and stratification, enables a representative sample of adults. However, heavy reliance on web-based responses may introduce internet bias, potentially underrepresenting non-internet households. Additionally, the questionnaire’s complexity may increase participant fatigue, affecting response completeness. The response rate of approximately 47.4% also indicates some level of attrition in the sample [@citemarquette].


# Idealized Methodology 

In designing a forecast for the upcoming US presidential election with a $100,000 budget, our methodology focuses on creating a representative survey that captures the voting intentions of likely voters across the United States. The objective is to gather reliable, high-quality data that supports a well-informed forecast through effective sampling, data validation, and aggregation techniques.

Our target population is voters aged 18 and above, with a sample size of approximately 10,000 responses, 200 responses from each state, to ensure  statistical significance at the national level and within key demographic groups. To achieve balanced representation, we will employ stratified random sampling based on age, gender, race/ethnicity, education, region, and urban/rural status. This approach will involve weighting responses using recent census data and voter turnout statistics to address any demographic discrepancies. 

We will combine online survey panels, social media outreach, and targeted telephone recruitment. These methods are chosen to increase accessibility for harder-to-reach demographics, such as older adults and rural residents. To encourage participation, we will offer modest incentives, such as a small monetary compensation or entry into a prize draw. All data collection will be conducted through a reliable survey platform—Google Forms. 

The survey itself will be concise and straightforward, focusing on voting intentions, key issues, and demographic information. For data validation, the survey will include attention-check questions as respondents are very likely to complete the form for an entry into a prize draw. We will also conduct multiple waves of the survey, we will adopt a "poll-of-polls" approach, aggregating responses from different waves while applying weights based on relevance. 

To mitigate biases such as non-response bias, social desirability bias, and order bias, our team will implement several strategies. We will send reminders to non-respondents to encourage participation, emphasizing the prize draw incentives to increase response rates. Survey questions will be carefully crafted to maintain neutral wording and avoid sensitive topics that might discourage honest responses. Additionally, within each wave of polls, we will randomize the order of questions to minimize the impact of question order on responses. These measures aim to enhance the reliability and accuracy of our survey results. 

To ensure data validity, IP addresses would be recorded to prevent multiple submissions from the same source. Additionally, cookies would be implemented to prevent users from retaking the survey on the same device. Finally, we will verify respondents' email addresses to ensure uniqueness.

Ethically, our approach prioritizes respondent privacy and data security. We will ensure that participants’ responses remain anonymous and that all data is handled securely. Transparency is also essential; respondents will be informed about the survey’s sponsorship, methodology, and data use.

The survey will be implemented on Google Forms, with a link provided in the appendix. We also included the questions in the appendix for better understandings. 

## Budget Allocation 

- Sampling and Data Collection (Advertisements and Recruitment Platforms): $40,000
- Participant Incentives (Prize Pool): $20,000
- Survey Design and Testing: $20,000
- Data Analysis and Validation: $20,000

# Idealized Survey 

The proposed survey is designed using Google Forms,
https://forms.gle/Vhmm1b1XnqTSoBWq8


## Survey Copy 

\includepdf[pages=-]{../other/Survey/Survey.pdf}



\newpage


# References


